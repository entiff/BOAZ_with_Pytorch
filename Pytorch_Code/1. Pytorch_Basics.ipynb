{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch Basics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [1] Pytorch Tensor Basic Usage\n",
    "\n",
    "- Create Tensor\n",
    "- Joining, Slicing\n",
    "- Math Operations\n",
    "- Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Create Tensor\n",
    "\n",
    "### 1) random numbers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T08:41:16.573579Z",
     "start_time": "2018-10-28T08:41:16.262616Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0.0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Pytorch Version 확인\n",
    "print(torch.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:49:52.638893Z",
     "start_time": "2018-10-18T13:49:52.631452Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0558, 0.3173, 0.0537],\n",
       "        [0.4884, 0.8494, 0.1010]])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.rand(size)\n",
    "# 0~1 사이의 연속균등분포에서 값을 뽑아 5x3 텐서를 생성합니다. ~U(0,1)\n",
    "x = torch.rand(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:49:53.118988Z",
     "start_time": "2018-10-18T13:49:53.110556Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 1.2258, -0.6182, -0.5214],\n",
       "        [-0.6280, -0.6622, -0.8422]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.randn(size)\n",
    "# randn의 경우 평균은 0, 표준편차는 1인 정규분포에서 값을 가져옵니다. ~z(0,1)\n",
    "x = torch.randn(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) empty, zeros, ones, arange, max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:49:54.685975Z",
     "start_time": "2018-10-18T13:49:54.681021Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.4013e-45, 0.0000e+00, 1.4013e-45],\n",
       "        [0.0000e+00, 0.0000e+00, 0.0000e+00]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.empty(size)\n",
    "# 원하는 크기의 빈 텐서를 생성합니다.\n",
    "x = torch.empty(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:49:55.172440Z",
     "start_time": "2018-10-18T13:49:55.168472Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.zeros(size)\n",
    "# 원하는 크기의 빈 텐서를 생성합니다.\n",
    "x = torch.zeros(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:49:55.722504Z",
     "start_time": "2018-10-18T13:49:55.718536Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.ones(size)\n",
    "# 원하는 크기의 1의 값을 가진 텐서를 생성합니다.\n",
    "x = torch.ones(2,3)\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-28T08:43:56.357472Z",
     "start_time": "2018-10-28T08:43:56.348021Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6047, 0.7987, 0.6312],\n",
      "        [0.6695, 0.7946, 0.7557]])\n",
      "tensor(0.7987)\n",
      "(tensor([0.7987, 0.7946]), tensor([1, 1]))\n",
      "tensor([1, 1])\n"
     ]
    }
   ],
   "source": [
    "# torch.max(input, dim, keepdim=False, out=None) -> (Tensor, LongTensor)\n",
    "# tensor의 최대값을 산출합니다.\n",
    "\n",
    "x = torch.rand(2,3)\n",
    "print(x)\n",
    "\n",
    "# 최대값을 출력합니다.\n",
    "print(torch.max(x))\n",
    "\n",
    "# 해당 차원에서 최대값과 그 위치를 출력합니다.\n",
    "print(torch.max(x,1))\n",
    "\n",
    "# 위치를 출력합니다.\n",
    "print(torch.max(x,1)[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) Tensor Data Type"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| Data type               | dtype                                         | Tensor types                 |\n",
    "|:-------------------------|:-----------------------------------------------|:------------------------------|\n",
    "| 32-bit floating point   | ``` torch.float32 ``` or ``` torch.float ```  | ``` torch.*.FloatTensor ```  |\n",
    "| 64-bit floating point   | ``` torch.float64 ``` or ``` torch.double ``` | ``` torch.*.DoubleTensor ``` |\n",
    "| 16-bit floating point   | ``` torch.float16 ``` or ``` torch.half ```   | ``` torch.*.HalfTensor ```   |\n",
    "| 16-bit integer (signed) | ``` torch.int16 ``` or ``` torch.short ```    | ``` torch.*.ShortTensor ```  |\n",
    "| 32-bit integer (signed) | ``` torch.int32 ``` or ``` torch.int ```      | ``` torch.*.IntTensor ```    |\n",
    "| 64-bit integer (signed) | ``` torch.int64 ``` or ``` torch.long ```     | ``` torch.*.LongTensor ```   |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:50:14.106543Z",
     "start_time": "2018-10-18T13:50:14.100075Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9982e-07,  4.5911e-41,  1.4013e-45],\n",
      "        [ 0.0000e+00,  1.4013e-45,  0.0000e+00]])\n",
      "tensor([[0, 0, 0],\n",
      "        [0, 0, 0]])\n",
      "tensor([0.0000, 0.5000, 1.0000, 1.5000, 2.0000, 2.5000], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# torch.empty(size, dtype=)\n",
    "# torch.zeros(size, dtype=)\n",
    "# torch.arange(start,end,dtype=)\n",
    "\n",
    "# torch에서 지원하는 다양한 data type을 옵션으로 지정할 수 있습니다.\n",
    "\n",
    "x = torch.empty(2,3, dtype=torch.float)\n",
    "y = torch.zeros(2,3, dtype = torch.long)\n",
    "z = torch.arange(0,3,step=0.5,dtype=torch.double)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T13:52:45.755168Z",
     "start_time": "2018-10-18T13:52:45.748223Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([5.5000, 3.0000])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.tensor(size or list, dtype = torch.floattensor) \n",
    "# 원하는 텐서를 바로 생성합니다.\n",
    "x = torch.tensor([5.5,3])\n",
    "x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:01:15.180723Z",
     "start_time": "2018-10-18T14:01:15.174242Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[-3.9982e-07,  4.5911e-41,  0.0000e+00],\n",
      "        [ 0.0000e+00,  1.4013e-45,  0.0000e+00]])\n",
      "tensor([2., 3.])\n"
     ]
    }
   ],
   "source": [
    "# torch.FloatTensor(size or list)\n",
    "x = torch.FloatTensor(2,3)\n",
    "print(x)\n",
    "x = torch.FloatTensor([2,3])\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:01:45.322911Z",
     "start_time": "2018-10-18T14:01:45.306086Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2, 3], dtype=torch.int32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor.type_as(tensor_type)\n",
    "# tensor 형 변환\n",
    "x = x.type_as(torch.IntTensor())\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) Tensor Size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:07:04.655354Z",
     "start_time": "2018-10-18T14:07:04.650890Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10, 12, 3, 3])\n",
      "10\n"
     ]
    }
   ],
   "source": [
    "# tensor.size()\n",
    "\n",
    "x = torch.FloatTensor(10,12,3,3)\n",
    "\n",
    "print(x.size()[:])\n",
    "print(x.size()[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Math Operations\n",
    "\n",
    "### 1) add, mul, div"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:13:27.357191Z",
     "start_time": "2018-10-18T14:13:27.348772Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "tensor([[ 2.,  4.,  6.],\n",
      "        [ 8., 10., 12.]])\n",
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.add()\n",
    "# 텐서의 값끼리 더합니다.\n",
    "\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "add = torch.add(x1, x2)\n",
    "\n",
    "# torch.add는 +로 대체 가능\n",
    "print(add)\n",
    "print(x1+x2)\n",
    "print(x1-x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:41:37.076027Z",
     "start_time": "2018-10-16T11:41:37.068067Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.2627, 0.3626, 1.0136],\n",
       "         [0.8887, 1.3566, 1.0730],\n",
       "         [1.2860, 1.5769, 1.1165],\n",
       "         [1.3708, 1.0847, 0.3843],\n",
       "         [0.8029, 0.1814, 0.9521]]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#차원이 다르더라도 안쪽 차원만 같으면 연산이 가능합니다.\n",
    "\n",
    "x = torch.rand(1,5,3)\n",
    "y = torch.rand(5,3)\n",
    "torch.add(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:21:21.937483Z",
     "start_time": "2018-10-18T14:21:21.929079Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n",
      "tensor([[ 1.,  4.,  9.],\n",
      "        [16., 25., 36.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.mul()\n",
    "# hadamard product, mxn, mxn 행렬 2개를 곱합니다. 덧셈에 대해 분배법칙을 따릅니다.\n",
    "\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x3 = torch.mul(x1,x2)\n",
    "\n",
    "# torch.mul은 *로 대체 가능\n",
    "print(x3)\n",
    "print(x1*x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:22:59.876800Z",
     "start_time": "2018-10-18T14:22:59.868342Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.div()\n",
    "\n",
    "x1 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x2 = torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "x3 = torch.div(x1,x2)\n",
    "\n",
    "# torch.div는 /로 대체 가능\n",
    "print(x3)\n",
    "print(x1/x2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) pow, exp, log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:26:45.051237Z",
     "start_time": "2018-10-18T14:26:45.045284Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5592, 0.9792, 0.1183, 0.4721],\n",
      "        [0.3496, 0.0501, 0.0639, 0.7570],\n",
      "        [0.0884, 0.2452, 0.2394, 0.2675]])\n",
      "tensor([[0.3127, 0.9588, 0.0140, 0.2228],\n",
      "        [0.1222, 0.0025, 0.0041, 0.5730],\n",
      "        [0.0078, 0.0601, 0.0573, 0.0716]]) \n",
      " tensor([[0.3127, 0.9588, 0.0140, 0.2228],\n",
      "        [0.1222, 0.0025, 0.0041, 0.5730],\n",
      "        [0.0078, 0.0601, 0.0573, 0.0716]])\n"
     ]
    }
   ],
   "source": [
    "# torch.pow(input,exponent)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "\n",
    "print(x1)\n",
    "# torch.pow는 **로 대체 가능\n",
    "print(torch.pow(x1,2),\"\\n\",x1**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:27:39.869050Z",
     "start_time": "2018-10-18T14:27:39.864586Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6543, 0.0180, 0.3945, 0.4455],\n",
      "        [0.3589, 0.1810, 0.3855, 0.4285],\n",
      "        [0.3367, 0.5431, 0.5213, 0.1646]])\n",
      "tensor([[1.9238, 1.0182, 1.4836, 1.5613],\n",
      "        [1.4317, 1.1984, 1.4703, 1.5349],\n",
      "        [1.4004, 1.7213, 1.6842, 1.1789]])\n"
     ]
    }
   ],
   "source": [
    "# torch.exp(tensor,out=None)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "\n",
    "print(x1)\n",
    "print(torch.exp(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:28:38.622326Z",
     "start_time": "2018-10-18T14:28:38.607413Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.6589, 0.3993, 0.9101, 0.2046],\n",
      "        [0.6485, 0.4819, 0.9604, 0.9543],\n",
      "        [0.8220, 0.1312, 0.9094, 0.2397]])\n",
      "tensor([[-0.4171, -0.9181, -0.0942, -1.5865],\n",
      "        [-0.4330, -0.7300, -0.0404, -0.0468],\n",
      "        [-0.1960, -2.0310, -0.0950, -1.4282]])\n"
     ]
    }
   ],
   "source": [
    "# torch.log(input,out=None)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "\n",
    "print(x1)\n",
    "print(torch.log(x1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:30:17.992784Z",
     "start_time": "2018-10-18T14:30:17.976412Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.4302, 0.6682, 0.1026, 0.8251, 0.7992],\n",
       "        [0.9914, 1.0428, 0.5859, 1.0643, 0.7807],\n",
       "        [0.5313, 0.6795, 0.1847, 0.8280, 0.7615]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.mm(matrix1, matrix2)\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "x2 = torch.rand(4,5)\n",
    "\n",
    "# torch.mul과 구분해서 사용해야함. mm은 matrix multiplication 연산을 수행\n",
    "torch.mm(x1,x2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:31:40.819367Z",
     "start_time": "2018-10-18T14:31:40.815375Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 3, 5])"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.bmm(batch_matrix1, batch_matrix2)\n",
    "\n",
    "x1 = torch.rand(10,3,4)\n",
    "x2 = torch.rand(10,4,5)\n",
    "\n",
    "# Batch끼리의 계산을 할 때 자주 사용됨\n",
    "torch.bmm(x1,x2).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![img](https://github.com/shwksl101/Pytorch-A-to-Z/blob/master/img/innerproduct.PNG?raw=true)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:35:25.100038Z",
     "start_time": "2018-10-18T14:35:25.092602Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(7)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.dot(tensor1, tensor2)\n",
    "\n",
    "torch.dot(torch.tensor([2,3]), torch.tensor([2,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:42:57.524955Z",
     "start_time": "2018-10-18T14:42:57.514572Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 4]) torch.Size([4, 3])\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 3, 4]), torch.Size([10, 4, 3]), torch.Size([10, 4, 3]))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.t(matrix)\n",
    "# tranpose\n",
    "\n",
    "x1 = torch.rand(3,4)\n",
    "print(x1.size(), x1.t().size())\n",
    "\n",
    "# torch.transpose(input,dim0,dim1)\n",
    "\n",
    "x1 = torch.rand(10,3,4)\n",
    "x1.size(), torch.transpose(x1,1,2).size(), x1.transpose(1,2).size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) view, item"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:51:42.774580Z",
     "start_time": "2018-10-16T11:51:42.767140Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4, 4])\n",
      "torch.Size([16]) tensor([-1.3522,  1.3358,  0.9015,  1.1398, -0.0273,  0.0384,  0.7265,  0.1332,\n",
      "         0.8172, -0.9961,  0.5111,  0.5698,  0.5933, -1.4054, -1.9977,  0.9106])\n",
      "torch.Size([2, 8]) tensor([[-1.3522,  1.3358,  0.9015,  1.1398, -0.0273,  0.0384,  0.7265,  0.1332],\n",
      "        [ 0.8172, -0.9961,  0.5111,  0.5698,  0.5933, -1.4054, -1.9977,  0.9106]])\n"
     ]
    }
   ],
   "source": [
    "# view()\n",
    "\n",
    "x = torch.randn(4,4)\n",
    "y = x.view(16)\n",
    "z = x.view(-1,8) # -1의 경우 다른 차원들로 유추합니다. 이 경우에는 2로 유추합니다.\n",
    "print(x.size())\n",
    "print(y.size(),y)\n",
    "print(z.size(),z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T11:54:28.425390Z",
     "start_time": "2018-10-16T11:54:28.417952Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([0.3563])\n",
      "0.3562667965888977\n"
     ]
    }
   ],
   "source": [
    "# item()\n",
    "\n",
    "x = torch.randn(1)\n",
    "print(x)\n",
    "print(x.item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 더 많은 연산은 다음의 링크에서 참고하세요 https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Tensor to Numpy, Numpy to Tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:05:14.994111Z",
     "start_time": "2018-10-16T12:05:14.990154Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:03:49.835180Z",
     "start_time": "2018-10-16T12:03:49.830247Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([1., 1., 1., 1., 1.])\n"
     ]
    }
   ],
   "source": [
    "a = torch.ones(5) # 1로 채워진 텐서를 생성합니다.\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:04:03.331822Z",
     "start_time": "2018-10-16T12:04:03.320915Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "# tensor.numpy()\n",
    "\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:05:53.759506Z",
     "start_time": "2018-10-16T12:05:53.752563Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2. 2. 2. 2. 2.]\n",
      "tensor([2., 2., 2., 2., 2.], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# torch.from_numpy(ndarray)\n",
    "\n",
    "a = np.ones(5) #a와 b는 연동됩니다.\n",
    "b = torch.from_numpy(a)\n",
    "\n",
    "np.add(a,1,out=a)\n",
    "\n",
    "print(a)\n",
    "print(b) #chartensor를 제외한 모든 tensor는 numpy로의 변환을 지원합니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Tensor on GPU\n",
    "\n",
    "단, GPU를 사용하기 위해서는 CUDA와 cudnn을 먼저 설치해야함."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T14:52:44.993367Z",
     "start_time": "2018-10-18T14:52:44.988429Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "x= torch.FloatTensor([[1,2,3],[4,5,6]])\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    x_cuda = x.cuda()\n",
    "else:\n",
    "    x_cuda = x.cpu()\n",
    "    \n",
    "print(x_cuda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-16T12:09:27.092831Z",
     "start_time": "2018-10-16T12:09:27.086847Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2., 3., 4.],\n",
      "        [5., 6., 7.]], device='cuda:0')\n",
      "tensor([[2., 3., 4.],\n",
      "        [5., 6., 7.]], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    y = torch.ones_like(x,device=device)\n",
    "    x = x.to(device)\n",
    "    z = x+y\n",
    "    print(z)\n",
    "    print(z.to(\"cpu\",torch.double)) #.to 기능을 tensor를 GPU로 연산할 수 있습니다"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Slicing, Joining\n",
    "\n",
    "### 1) Joining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:03:42.155801Z",
     "start_time": "2018-10-18T15:03:42.147864Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.,  2.,  3.,  7.,  8.,  9.],\n",
      "        [ 4.,  5.,  6., 10., 11., 12.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.cat(seq, dim=0)\n",
    "# dim을 기준으로 tensor를 합칩니다.\n",
    "# dim = 0은 행, dim = 1은 열 기준입니다.\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "y = torch.FloatTensor([[7,8,9],\n",
    "                       [10,11,12]])\n",
    "z1 = torch.cat([x,y],dim = 0)\n",
    "z2 = torch.cat([x,y],dim = 1)\n",
    "\n",
    "print(x)\n",
    "print(y)\n",
    "print(z1)\n",
    "print(z2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:06:42.528676Z",
     "start_time": "2018-10-18T15:06:42.521732Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [1., 2., 3.]]) \n",
      " tensor([[1., 1.],\n",
      "        [2., 2.],\n",
      "        [3., 3.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.stack(sequence,dim=0)\n",
    "# dim을 기준으로 쌓습니다.\n",
    "\n",
    "x = torch.FloatTensor([1,2,3])\n",
    "x_stack = torch.stack([x,x],dim=0)\n",
    "x_stack2 = torch.stack([x,x],dim=1)\n",
    "\n",
    "print(x_stack,\"\\n\",x_stack2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) Slicing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:26:40.350021Z",
     "start_time": "2018-10-18T15:26:40.340105Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 1.,  2.,  3.],\n",
      "        [ 4.,  5.,  6.],\n",
      "        [ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "tensor([[ 1.],\n",
      "        [ 4.],\n",
      "        [ 7.],\n",
      "        [10.]])\n",
      "tensor([[ 2.],\n",
      "        [ 5.],\n",
      "        [ 8.],\n",
      "        [11.]])\n",
      "tensor([[ 3.],\n",
      "        [ 6.],\n",
      "        [ 9.],\n",
      "        [12.]])\n"
     ]
    }
   ],
   "source": [
    "# torch.chunk(tensor, chunks, dim=0)\n",
    "# tensor를 chunk 단위로 쪼갭니다.\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "y = torch.FloatTensor([[7,8,9],\n",
    "                       [10,11,12]])\n",
    "z1 = torch.cat([x,y],dim = 0)\n",
    "\n",
    "x_1, x_2 = torch.chunk(z1,2,dim=0)\n",
    "y_1, y_2, y_3 = torch.chunk(z1,3,dim=1)\n",
    "\n",
    "print(z1)\n",
    "print(x_1)\n",
    "print(x_2)\n",
    "print(y_1)\n",
    "print(y_2)\n",
    "print(y_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:30:36.566401Z",
     "start_time": "2018-10-18T15:30:36.560913Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 2., 3.],\n",
      "        [4., 5., 6.]])\n",
      "tensor([[ 7.,  8.,  9.],\n",
      "        [10., 11., 12.]])\n",
      "(tensor([[ 1.,  2.],\n",
      "        [ 4.,  5.],\n",
      "        [ 7.,  8.],\n",
      "        [10., 11.]]), tensor([[ 3.],\n",
      "        [ 6.],\n",
      "        [ 9.],\n",
      "        [12.]]))\n"
     ]
    }
   ],
   "source": [
    "# torch.splot(tensor,splot_size,dim=0)\n",
    "\n",
    "x = torch.FloatTensor([[1,2,3],\n",
    "                       [4,5,6]])\n",
    "y = torch.FloatTensor([[7,8,9],\n",
    "                       [10,11,12]])\n",
    "z1 = torch.cat([x,y],dim = 0)\n",
    "\n",
    "x1,x2 = torch.split(z1,2,dim=0)\n",
    "y1 = torch.split(z1,2,dim=1)\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) squeezing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:32:18.274598Z",
     "start_time": "2018-10-18T15:32:18.270607Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([10, 1, 3, 1, 4]), torch.Size([10, 3, 4]))"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.squeez(input, dim=None)\n",
    "# 1짜리 차원을 줄입니다.\n",
    "\n",
    "x1 = torch.FloatTensor(10,1,3,1,4)\n",
    "x2 = torch.squeeze(x1)\n",
    "\n",
    "x1.size(), x2.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:33:42.680785Z",
     "start_time": "2018-10-18T15:33:42.668846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2, 3]), torch.Size([1, 10, 3, 4]))"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# torch.unsqueeze(input,dim=None)\n",
    "# 1짜리 차원을 더합니다.\n",
    "\n",
    "x1 = torch.FloatTensor(10,3,4)\n",
    "x2 = torch.unsqueeze(x1,dim=0)\n",
    "\n",
    "x.size(), x2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2018-10-18T15:34:35.243740Z",
     "start_time": "2018-10-18T15:34:35.234338Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[5.2884, 4.4637, 7.2311, 0.3083],\n",
       "         [0.6230, 0.5624, 7.0414, 0.6258],\n",
       "         [6.6145, 6.7477, 2.8904, 8.1059]]),\n",
       " tensor([[-0.0589, -0.0038, -0.0622, -0.0431],\n",
       "         [ 0.0394, -0.0435,  0.1642, -0.0922],\n",
       "         [ 0.1898, -0.1107, -0.1054, -0.4502]]),\n",
       " tensor([[3.1415, 3.1415, 3.1415, 3.1415],\n",
       "         [3.1415, 3.1415, 3.1415, 3.1415],\n",
       "         [3.1415, 3.1415, 3.1415, 3.1415]]))"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn.init as init\n",
    "\n",
    "x1 = init.uniform_(torch.FloatTensor(3,4),a=0,b=9) \n",
    "x2 = init.normal_(torch.FloatTensor(3,4),std=0.2)\n",
    "x3 = init.constant_(torch.FloatTensor(3,4),3.1415)\n",
    "\n",
    "x1,x2,x3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [2] Autograd\n",
    "\n",
    "### Autograd Package\n",
    "\n",
    "- Autograd 패키지는 tensor의 모든 연산에 자동 미분을 제공합니다. 이는 define-by-run의 프레임워크로 코드를 어떻게 작성하느냐에 따라 역전파가 정의된다는 뜻입니다. 역전파는 학습과정의 매 단계마다 달라집니다.\n",
    "\n",
    "- .requires_grad 속성을 True로 설정하면 해당 tensor의 모든 연산을 추적합니다. 계산이 완료된 후 .backward()를 호출해 gradient를 자동으로 계산할 수 있습니다. 이 tensor의 gradient는 .grad에 누적됩니다.\n",
    "\n",
    "- 연산 기록을 추적하는 것을 멈추기 위해 코드 블럭을 with torch.no_grad():로 감쌀 수 있습니다. gradient는 필요 없지만 requires_grad=True가 설정되어 학습 가능한 Parameter(매개변수)를 갖는 모델을 평가할 때 유용합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "x = torch.ones(2,2,requires_grad=True) #tensor를 생성하고 requires_grad=True로 연산을 기록합니다.\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3., 3.],\n",
      "        [3., 3.]], grad_fn=<AddBackward0>)\n"
     ]
    }
   ],
   "source": [
    "y = x+2 #gradient function이 자동으로 포함됩니다.\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[27., 27.],\n",
      "        [27., 27.]], grad_fn=<MulBackward0>) tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "z = y*y*3\n",
    "out = z.mean()\n",
    "print(z,out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n",
      "None\n",
      "True\n",
      "<SumBackward0 object at 0x000002431D3F6438>\n"
     ]
    }
   ],
   "source": [
    "a = torch.randn(2,2)\n",
    "a = ((a*3)/(a-1)) \n",
    "print(a.requires_grad)\n",
    "print(a.grad_fn) # 사용자가 만든 텐서의 grad_fn은 none입니다.\n",
    "a.requires_grad_(True)\n",
    "print(a.requires_grad)\n",
    "b = (a*a).sum()\n",
    "print(b.grad_fn) #requires_grad_(True)로 지정하고 연산하면 이렇게 grad_fn가 생깁니다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(27., grad_fn=<MeanBackward1>)\n"
     ]
    }
   ],
   "source": [
    "print(out) # out = 3(x+2)*2\n",
    "out.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1., 1.],\n",
      "        [1., 1.]], requires_grad=True)\n",
      "tensor([[4.5000, 4.5000],\n",
      "        [4.5000, 4.5000]])\n"
     ]
    }
   ],
   "source": [
    "print(x)\n",
    "print(x.grad) # d(out)/dx 를 출력합니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-4.0405,  2.6186, -9.0408], grad_fn=<MulBackward0>) tensor(10.2430)\n",
      "tensor([ -8.0810,   5.2371, -18.0817], grad_fn=<MulBackward0>) tensor(20.4860)\n",
      "tensor([-16.1620,  10.4743, -36.1634], grad_fn=<MulBackward0>) tensor(40.9721)\n",
      "tensor([-32.3241,  20.9486, -72.3267], grad_fn=<MulBackward0>) tensor(81.9442)\n",
      "tensor([ -64.6482,   41.8971, -144.6535], grad_fn=<MulBackward0>) tensor(163.8883)\n",
      "tensor([-129.2963,   83.7943, -289.3070], grad_fn=<MulBackward0>) tensor(327.7767)\n",
      "tensor([-258.5927,  167.5885, -578.6140], grad_fn=<MulBackward0>) tensor(655.5533)\n",
      "tensor([ -517.1854,   335.1770, -1157.2279], grad_fn=<MulBackward0>) tensor(1311.1067)\n"
     ]
    }
   ],
   "source": [
    "x = torch.randn(3,requires_grad=True)\n",
    "\n",
    "y=x*2\n",
    "\n",
    "while y.data.norm() < 1000:\n",
    "    \n",
    "    #data.norm()은 점들 사이의 유클리디안 거리를 나타냅니다\n",
    "    #torch.sqrt(torch.sum(torch.pow(y, 2)))\n",
    "    \n",
    "    y = y*2\n",
    "    \n",
    "    print(y,y.data.norm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -517.1854,   335.1770, -1157.2279], grad_fn=<MulBackward0>)\n",
      "tensor([5.1200e+01, 5.1200e+02, 5.1200e-02])\n"
     ]
    }
   ],
   "source": [
    "gradients = torch.tensor([0.1,1.0,0.0001],dtype=torch.float)\n",
    "print(y)\n",
    "y.backward(gradients)\n",
    "print(x.grad) # d(y)/d(x) 를 출력합니다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n",
      "True\n",
      "False\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "print(x.requires_grad)\n",
    "print((x**2).requires_grad)\n",
    "\n",
    "with torch.no_grad():\n",
    "    print((x**2).requires_grad) #tensor들의 연산 기록 추적을 막을 수 있습니다.\n",
    "     \n",
    "print((x**2).requires_grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- autograd package에 대한 더 자세한 정보는 다음의 링크를 참고하세요. https://pytorch.org/docs/stable/torch.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## [3] Neural Network 기본 실습"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import transforms\n",
    "from torchvision import datasets\n",
    "\n",
    "batch_size = 32\n",
    "learning_rate = 0.01\n",
    "num_epochs = 5\n",
    "\n",
    "# MNIST Dataset DataLoader\n",
    "train_dataset = datasets.MNIST(root='./data', train=True,\n",
    "                        transform=transforms.ToTensor(), download=True)\n",
    "test_dataset = datasets.MNIST(root='./data', train=False,\n",
    "                        transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Neural Network Modeling\n",
    "class Neuralnetwork(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(Neuralnetwork, self).__init__()\n",
    "        self.layer1 = nn.Linear(28*28, 100)\n",
    "        self.layer2 = nn.Linear(100, 200)\n",
    "        self.layer3 = nn.Linear(200, num_classes)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        out = x.view(x.size(0), -1)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        \n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Model\n",
    "model = Neuralnetwork()\n",
    "\n",
    "# Loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/5], Step [100/1875], Loss: 2.1738\n",
      "Epoch [1/5], Step [200/1875], Loss: 1.8190\n",
      "Epoch [1/5], Step [300/1875], Loss: 1.3110\n",
      "Epoch [1/5], Step [400/1875], Loss: 1.0612\n",
      "Epoch [1/5], Step [500/1875], Loss: 0.8907\n",
      "Epoch [1/5], Step [600/1875], Loss: 0.6475\n",
      "Epoch [1/5], Step [700/1875], Loss: 0.9325\n",
      "Epoch [1/5], Step [800/1875], Loss: 0.5230\n",
      "Epoch [1/5], Step [900/1875], Loss: 0.4543\n",
      "Epoch [1/5], Step [1000/1875], Loss: 0.3658\n",
      "Epoch [1/5], Step [1100/1875], Loss: 0.4579\n",
      "Epoch [1/5], Step [1200/1875], Loss: 0.3607\n",
      "Epoch [1/5], Step [1300/1875], Loss: 1.0041\n",
      "Epoch [1/5], Step [1400/1875], Loss: 0.3750\n",
      "Epoch [1/5], Step [1500/1875], Loss: 0.4524\n",
      "Epoch [1/5], Step [1600/1875], Loss: 0.3276\n",
      "Epoch [1/5], Step [1700/1875], Loss: 0.6145\n",
      "Epoch [1/5], Step [1800/1875], Loss: 0.1755\n",
      "Epoch [2/5], Step [100/1875], Loss: 0.3312\n",
      "Epoch [2/5], Step [200/1875], Loss: 0.2156\n",
      "Epoch [2/5], Step [300/1875], Loss: 0.2872\n",
      "Epoch [2/5], Step [400/1875], Loss: 0.2551\n",
      "Epoch [2/5], Step [500/1875], Loss: 0.5129\n",
      "Epoch [2/5], Step [600/1875], Loss: 0.5665\n",
      "Epoch [2/5], Step [700/1875], Loss: 0.2876\n",
      "Epoch [2/5], Step [800/1875], Loss: 0.2037\n",
      "Epoch [2/5], Step [900/1875], Loss: 0.2412\n",
      "Epoch [2/5], Step [1000/1875], Loss: 0.3784\n",
      "Epoch [2/5], Step [1100/1875], Loss: 0.4337\n",
      "Epoch [2/5], Step [1200/1875], Loss: 0.4790\n",
      "Epoch [2/5], Step [1300/1875], Loss: 0.6514\n",
      "Epoch [2/5], Step [1400/1875], Loss: 0.2646\n",
      "Epoch [2/5], Step [1500/1875], Loss: 0.1761\n",
      "Epoch [2/5], Step [1600/1875], Loss: 0.2928\n",
      "Epoch [2/5], Step [1700/1875], Loss: 0.3349\n",
      "Epoch [2/5], Step [1800/1875], Loss: 0.2897\n",
      "Epoch [3/5], Step [100/1875], Loss: 0.5608\n",
      "Epoch [3/5], Step [200/1875], Loss: 0.3884\n",
      "Epoch [3/5], Step [300/1875], Loss: 0.2319\n",
      "Epoch [3/5], Step [400/1875], Loss: 0.2020\n",
      "Epoch [3/5], Step [500/1875], Loss: 0.0875\n",
      "Epoch [3/5], Step [600/1875], Loss: 0.2497\n",
      "Epoch [3/5], Step [700/1875], Loss: 0.6126\n",
      "Epoch [3/5], Step [800/1875], Loss: 0.5027\n",
      "Epoch [3/5], Step [900/1875], Loss: 0.3505\n",
      "Epoch [3/5], Step [1000/1875], Loss: 0.6006\n",
      "Epoch [3/5], Step [1100/1875], Loss: 0.1311\n",
      "Epoch [3/5], Step [1200/1875], Loss: 0.2918\n",
      "Epoch [3/5], Step [1300/1875], Loss: 0.6043\n",
      "Epoch [3/5], Step [1400/1875], Loss: 0.3964\n",
      "Epoch [3/5], Step [1500/1875], Loss: 0.4645\n",
      "Epoch [3/5], Step [1600/1875], Loss: 0.1921\n",
      "Epoch [3/5], Step [1700/1875], Loss: 0.2920\n",
      "Epoch [3/5], Step [1800/1875], Loss: 0.2115\n",
      "Epoch [4/5], Step [100/1875], Loss: 0.2902\n",
      "Epoch [4/5], Step [200/1875], Loss: 0.2369\n",
      "Epoch [4/5], Step [300/1875], Loss: 0.4072\n",
      "Epoch [4/5], Step [400/1875], Loss: 0.3491\n",
      "Epoch [4/5], Step [500/1875], Loss: 0.3329\n",
      "Epoch [4/5], Step [600/1875], Loss: 0.3815\n",
      "Epoch [4/5], Step [700/1875], Loss: 0.3515\n",
      "Epoch [4/5], Step [800/1875], Loss: 0.1632\n",
      "Epoch [4/5], Step [900/1875], Loss: 0.2081\n",
      "Epoch [4/5], Step [1000/1875], Loss: 0.2590\n",
      "Epoch [4/5], Step [1100/1875], Loss: 0.2028\n",
      "Epoch [4/5], Step [1200/1875], Loss: 0.4058\n",
      "Epoch [4/5], Step [1300/1875], Loss: 0.2675\n",
      "Epoch [4/5], Step [1400/1875], Loss: 0.2820\n",
      "Epoch [4/5], Step [1500/1875], Loss: 0.0890\n",
      "Epoch [4/5], Step [1600/1875], Loss: 0.1799\n",
      "Epoch [4/5], Step [1700/1875], Loss: 0.2510\n",
      "Epoch [4/5], Step [1800/1875], Loss: 0.3415\n",
      "Epoch [5/5], Step [100/1875], Loss: 0.2444\n",
      "Epoch [5/5], Step [200/1875], Loss: 0.2806\n",
      "Epoch [5/5], Step [300/1875], Loss: 0.3060\n",
      "Epoch [5/5], Step [400/1875], Loss: 0.2189\n",
      "Epoch [5/5], Step [500/1875], Loss: 0.1377\n",
      "Epoch [5/5], Step [600/1875], Loss: 0.3259\n",
      "Epoch [5/5], Step [700/1875], Loss: 0.5284\n",
      "Epoch [5/5], Step [800/1875], Loss: 0.5427\n",
      "Epoch [5/5], Step [900/1875], Loss: 0.4386\n",
      "Epoch [5/5], Step [1000/1875], Loss: 0.4097\n",
      "Epoch [5/5], Step [1100/1875], Loss: 0.2295\n",
      "Epoch [5/5], Step [1200/1875], Loss: 0.8744\n",
      "Epoch [5/5], Step [1300/1875], Loss: 0.4499\n",
      "Epoch [5/5], Step [1400/1875], Loss: 0.2459\n",
      "Epoch [5/5], Step [1500/1875], Loss: 0.4004\n",
      "Epoch [5/5], Step [1600/1875], Loss: 0.2122\n",
      "Epoch [5/5], Step [1700/1875], Loss: 0.1240\n",
      "Epoch [5/5], Step [1800/1875], Loss: 0.1623\n"
     ]
    }
   ],
   "source": [
    "# Traing the model\n",
    "for epoch in range(num_epochs):\n",
    "    for i, (img, label) in enumerate(train_loader, 1):\n",
    "        img, label = Variable(img), Variable(label)\n",
    "        out = model(img)\n",
    "        loss = criterion(out, label)\n",
    "        \n",
    "        # Backward and optimize\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if (i+1) % 100 == 0:\n",
    "            print('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, i+1, len(train_loader), loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 91.99 %\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "model.eval()\n",
    "\n",
    "correct = 0\n",
    "total = 0\n",
    "for img, label in test_loader:\n",
    "    out = model(img)\n",
    "    _, predicted = torch.max(out.data, 1)\n",
    "    total += label.size(0)\n",
    "    correct += (predicted == label).sum().item()\n",
    "    \n",
    "print('Test Accuracy of the model on the 10000 test images: {} %'.format(100 * correct / total))\n",
    "\n",
    "# Save the model checkpoint\n",
    "torch.save(model.state_dict(), 'model_nn.ckpt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### [과제] Neural Network의 구조를 변경하여, MNIST Classification Accuracy 92% 이상으로 만들기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": false,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
